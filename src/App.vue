<template>
  <div class="app-container">
    <Live2DRenderer ref="renderer" />
    <BubbleDialog v-if="currentText || currentImageUrl" :text="currentText" :imageUrl="currentImageUrl" />

    <!-- è¿æ¥çŠ¶æ€æŒ‡ç¤ºå™¨ -->
    <div class="connection-status" :class="{ connected: connectionStore.connected }">
      <span v-if="connectionStore.connected">ğŸŸ¢ å·²è¿æ¥</span>
      <span v-else>ğŸ”´ æœªè¿æ¥</span>
    </div>

    <!-- å›¾ç‰‡å‘é€æŒ‰é’® -->
    <div class="image-send-button" @click="triggerImageSelect" title="å‘é€å›¾ç‰‡">
      ğŸ“·
    </div>
    <input
      ref="imageInput"
      type="file"
      accept="image/*"
      @change="handleImageSelect"
      style="display: none"
    />

    <!-- è¯­éŸ³å½•éŸ³æŒ‰é’® -->
    <div
      class="voice-record-button"
      :class="{ recording: isRecording }"
      @mousedown="startRecording"
      @mouseup="stopRecording"
      @mouseleave="stopRecording"
      :title="isRecording ? 'æ¾å¼€å‘é€' : 'æŒ‰ä½å½•éŸ³'"
    >
      ğŸ¤
    </div>

    <!-- è°ƒè¯•é¢æ¿ï¼ˆå¯é€‰ï¼‰ -->
    <div v-if="showDebug" class="debug-panel">
      <h3>è°ƒè¯•ä¿¡æ¯</h3>
      <p>è¿æ¥çŠ¶æ€: {{ connectionStore.connected ? 'å·²è¿æ¥' : 'æœªè¿æ¥' }}</p>
      <p>å½“å‰æ–‡æœ¬: {{ currentText || 'æ— ' }}</p>
      <button @click="testMotion">æµ‹è¯•åŠ¨ä½œ</button>
      <button @click="testExpression">æµ‹è¯•è¡¨æƒ…</button>
      <button @click="testPerform">æµ‹è¯•è¡¨æ¼”</button>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted } from 'vue'
import { useConnectionStore } from './stores/connection'
import Live2DRenderer from './components/Live2DRenderer.vue'
import BubbleDialog from './components/BubbleDialog.vue'
import type { SaveMessageParams } from './types/history'

const connectionStore = useConnectionStore()
const renderer = ref()
const currentText = ref('')
const currentImageUrl = ref('')
const showDebug = ref(false)
const imageInput = ref<HTMLInputElement>()
const isRecording = ref(false)
const mediaRecorder = ref<MediaRecorder | null>(null)
const audioChunks = ref<Blob[]>([])
const currentConversationId = ref<number | null>(null)

// ç›‘å¬é”®ç›˜äº‹ä»¶æ˜¾ç¤º/éšè—è°ƒè¯•é¢æ¿
onMounted(async () => {
  // åˆå§‹åŒ–å½“å‰å¯¹è¯
  await initializeConversation()

  window.addEventListener('keydown', (e) => {
    if (e.key === 'F12' || (e.ctrlKey && e.shiftKey && e.key === 'D')) {
      e.preventDefault()
      showDebug.value = !showDebug.value
    }
  })

  // è¿æ¥åˆ°æœåŠ¡å™¨
  connectionStore.connect('ws://localhost:8765/ws', '')

  // ç›‘å¬è¡¨æ¼”æŒ‡ä»¤
  connectionStore.onPerform((sequence) => {
    executePerformSequence(sequence)
  })

  // ç›‘å¬æ¥è‡ªè®¾ç½®çª—å£çš„æ’­æ”¾æŒ‡ä»¤
  if (window.electronAPI?.onPlayMotion) {
    window.electronAPI.onPlayMotion((group, index) => {
      console.log(`[é¢„è§ˆ] æ’­æ”¾åŠ¨ä½œ: ${group} #${index}`)
      renderer.value?.playMotion(group, index)
    })
  }

  if (window.electronAPI?.onPlayExpression) {
    window.electronAPI.onPlayExpression((expressionId) => {
      console.log(`[é¢„è§ˆ] æ’­æ”¾è¡¨æƒ…: ${expressionId}`)
      renderer.value?.setExpression(expressionId)
    })
  }
})

// åˆå§‹åŒ–å½“å‰å¯¹è¯
const initializeConversation = async () => {
  if (!window.electronAPI) return

  try {
    const activeConv = await window.electronAPI.dbGetActiveConversation()
    if (activeConv) {
      currentConversationId.value = activeConv.id
      console.log('[å¯¹è¯] åŠ è½½æ¿€æ´»å¯¹è¯:', activeConv.id)
    } else {
      // æ²¡æœ‰æ¿€æ´»å¯¹è¯ï¼Œåˆ›å»ºé»˜è®¤å¯¹è¯
      const convId = await window.electronAPI.dbCreateConversation('é»˜è®¤å¯¹è¯')
      currentConversationId.value = convId
      console.log('[å¯¹è¯] åˆ›å»ºæ–°å¯¹è¯:', convId)
    }
  } catch (error) {
    console.error('[å¯¹è¯] åˆå§‹åŒ–å¤±è´¥:', error)
  }
}

// è·å–å½“å‰å¯¹è¯IDï¼ˆç¡®ä¿å­˜åœ¨ï¼‰
const getCurrentConversationId = async (): Promise<number> => {
  if (currentConversationId.value !== null) {
    return currentConversationId.value
  }

  // å¦‚æœæ²¡æœ‰å½“å‰å¯¹è¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°å¯¹è¯
  if (!window.electronAPI) {
    throw new Error('electronAPI æœªåˆå§‹åŒ–')
  }

  const convId = await window.electronAPI.dbCreateConversation('æ–°å¯¹è¯')
  currentConversationId.value = convId
  console.log('[å¯¹è¯] åˆ›å»ºæ–°å¯¹è¯:', convId)
  return convId
}

// ä¿å­˜AIæ¶ˆæ¯
const saveAIMessage = async (messageType: string, content: string, rawData: any) => {
  if (!window.electronAPI) {
    console.warn('[æ¶ˆæ¯] electronAPI æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜æ¶ˆæ¯')
    return
  }

  try {
    const convId = await getCurrentConversationId()
    const params: SaveMessageParams = {
      conversation_id: convId,
      sender: 'ai',
      message_type: messageType as any,
      content,
      raw_data: JSON.stringify(rawData),
      timestamp: Date.now()
    }

    await window.electronAPI.dbSaveMessage(params)
    console.log(`[æ¶ˆæ¯] ä¿å­˜AIæ¶ˆæ¯æˆåŠŸ: ç±»å‹=${messageType}, å¯¹è¯ID=${convId}`)

    // æ›´æ–°ç»Ÿè®¡
    await updateDailyStatistics({
      ai_messages: 1,
      total_messages: 1,
      [`${messageType}_messages`]: 1
    })
  } catch (error) {
    console.error('[æ¶ˆæ¯] ä¿å­˜AIæ¶ˆæ¯å¤±è´¥:', error)
  }
}

// ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
const saveUserMessage = async (messageType: string, content: string, rawData: any) => {
  if (!window.electronAPI) {
    console.warn('[æ¶ˆæ¯] electronAPI æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜æ¶ˆæ¯')
    return
  }

  try {
    const convId = await getCurrentConversationId()
    const params: SaveMessageParams = {
      conversation_id: convId,
      sender: 'user',
      message_type: messageType as any,
      content,
      raw_data: JSON.stringify(rawData),
      timestamp: Date.now()
    }

    await window.electronAPI.dbSaveMessage(params)
    console.log(`[æ¶ˆæ¯] ä¿å­˜ç”¨æˆ·æ¶ˆæ¯æˆåŠŸ: ç±»å‹=${messageType}, å¯¹è¯ID=${convId}`)

    // æ›´æ–°ç»Ÿè®¡
    await updateDailyStatistics({
      user_messages: 1,
      total_messages: 1,
      [`${messageType}_messages`]: 1
    })
  } catch (error) {
    console.error('[æ¶ˆæ¯] ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å¤±è´¥:', error)
  }
}

// æ›´æ–°æ¯æ—¥ç»Ÿè®¡
const updateDailyStatistics = async (updates: Record<string, number>) => {
  if (!window.electronAPI) return

  try {
    const today = new Date().toISOString().split('T')[0]
    await window.electronAPI.dbUpdateStatistics({
      stat_date: today,
      ...updates
    })
  } catch (error) {
    console.error('[ç»Ÿè®¡] æ›´æ–°ç»Ÿè®¡å¤±è´¥:', error)
  }
}

// æ‰§è¡Œè¡¨æ¼”åºåˆ—
const executePerformSequence = async (sequence: any[]) => {
  for (const item of sequence) {
    if (item.type === 'text') {
      currentText.value = item.content
      // ä¿å­˜æ–‡æœ¬æ¶ˆæ¯
      await saveAIMessage('text', item.content || '', item)
      await delay(item.duration || 3000)
      currentText.value = ''
    }

    if (item.type === 'image') {
      currentImageUrl.value = item.url
      // ä¿å­˜å›¾ç‰‡æ¶ˆæ¯
      await saveAIMessage('image', item.url || '', item)
      await delay(item.duration || 5000)
      currentImageUrl.value = ''
    }

    if (item.type === 'motion') {
      renderer.value?.playMotion(item.group, item.index)
      // ä¿å­˜åŠ¨ä½œæ¶ˆæ¯
      await saveAIMessage('motion', `${item.group}:${item.index}`, item)
    }

    if (item.type === 'expression') {
      renderer.value?.setExpression(item.id)
      // ä¿å­˜è¡¨æƒ…æ¶ˆæ¯
      await saveAIMessage('expression', item.id || '', item)
    }

    if (item.type === 'tts') {
      await playTTS(item)
      // ä¿å­˜TTSæ¶ˆæ¯
      await saveAIMessage('tts', item.text || item.url || '', item)
    }
  }
}

// å»¶è¿Ÿå‡½æ•°
const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms))

// æ’­æ”¾TTSéŸ³é¢‘
const playTTS = async (item: any) => {
  const ttsMode = item.ttsMode || 'remote'

  if (ttsMode === 'remote' && item.url) {
    // è¿œç¨‹TTSæ¨¡å¼:æ’­æ”¾éŸ³é¢‘URL
    return new Promise<void>((resolve, reject) => {
      const audio = new Audio(item.url)
      audio.volume = item.volume || 1.0
      audio.playbackRate = item.speed || 1.0

      audio.onended = () => resolve()
      audio.onerror = (e) => {
        console.error('[TTS] éŸ³é¢‘æ’­æ”¾å¤±è´¥:', e)
        reject(e)
      }

      audio.play().catch(e => {
        console.error('[TTS] éŸ³é¢‘æ’­æ”¾å¤±è´¥:', e)
        reject(e)
      })
    })
  } else if (ttsMode === 'local' && item.text) {
    // æœ¬åœ°TTSæ¨¡å¼:ä½¿ç”¨Web Speech API
    return new Promise<void>((resolve, reject) => {
      if (!('speechSynthesis' in window)) {
        console.error('[TTS] æµè§ˆå™¨ä¸æ”¯æŒWeb Speech API')
        reject(new Error('æµè§ˆå™¨ä¸æ”¯æŒWeb Speech API'))
        return
      }

      const utterance = new SpeechSynthesisUtterance(item.text)
      utterance.voice = item.voice || null
      utterance.volume = item.volume || 1.0
      utterance.rate = item.speed || 1.0

      utterance.onend = () => resolve()
      utterance.onerror = (e) => {
        console.error('[TTS] è¯­éŸ³åˆæˆå¤±è´¥:', e)
        reject(e)
      }

      window.speechSynthesis.speak(utterance)
    })
  } else {
    console.warn('[TTS] æ— æ•ˆçš„TTSé…ç½®:', item)
  }
}

// è§¦å‘å›¾ç‰‡é€‰æ‹©
const triggerImageSelect = () => {
  if (!connectionStore.connected) {
    console.warn('[å›¾ç‰‡] æœªè¿æ¥åˆ°æœåŠ¡å™¨')
    return
  }
  imageInput.value?.click()
}

// å¤„ç†å›¾ç‰‡é€‰æ‹©
const handleImageSelect = async (event: Event) => {
  const target = event.target as HTMLInputElement
  const file = target.files?.[0]

  if (!file) return

  try {
    // è¯»å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºBase64
    const reader = new FileReader()
    reader.onload = async () => {
      const base64Data = reader.result as string
      const messageData = {
        type: 'image',
        data: base64Data
      }

      // å‘é€å›¾ç‰‡æ¶ˆæ¯
      connectionStore.sendMessage([messageData])

      // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
      await saveUserMessage('image', base64Data.substring(0, 100) + '...', messageData)

      console.log('[å›¾ç‰‡] å·²å‘é€å›¾ç‰‡')
    }

    reader.onerror = () => {
      console.error('[å›¾ç‰‡] è¯»å–å›¾ç‰‡å¤±è´¥')
    }

    reader.readAsDataURL(file)
  } catch (error) {
    console.error('[å›¾ç‰‡] å¤„ç†å›¾ç‰‡å¤±è´¥:', error)
  } finally {
    // æ¸…ç©ºinput,å…è®¸é‡å¤é€‰æ‹©åŒä¸€æ–‡ä»¶
    target.value = ''
  }
}

// å¼€å§‹å½•éŸ³
const startRecording = async () => {
  if (!connectionStore.connected) {
    console.warn('[å½•éŸ³] æœªè¿æ¥åˆ°æœåŠ¡å™¨')
    return
  }

  if (isRecording.value) return

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    mediaRecorder.value = new MediaRecorder(stream)
    audioChunks.value = []

    mediaRecorder.value.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.value.push(event.data)
      }
    }

    mediaRecorder.value.onstop = async () => {
      const audioBlob = new Blob(audioChunks.value, { type: 'audio/webm' })
      await sendVoiceMessage(audioBlob)

      // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
      stream.getTracks().forEach(track => track.stop())
    }

    mediaRecorder.value.start()
    isRecording.value = true
    console.log('[å½•éŸ³] å¼€å§‹å½•éŸ³')
  } catch (error) {
    console.error('[å½•éŸ³] å¯åŠ¨å½•éŸ³å¤±è´¥:', error)
  }
}

// åœæ­¢å½•éŸ³
const stopRecording = () => {
  if (!isRecording.value || !mediaRecorder.value) return

  mediaRecorder.value.stop()
  isRecording.value = false
  console.log('[å½•éŸ³] åœæ­¢å½•éŸ³')
}

// å‘é€è¯­éŸ³æ¶ˆæ¯
const sendVoiceMessage = async (audioBlob: Blob) => {
  try {
    // è½¬æ¢ä¸ºBase64
    const reader = new FileReader()
    reader.onload = async () => {
      const base64Data = reader.result as string
      const messageData = {
        type: 'voice',
        data: base64Data,
        sttMode: 'remote'
      }

      // å‘é€è¯­éŸ³æ¶ˆæ¯
      connectionStore.sendMessage([messageData])

      // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
      await saveUserMessage('voice', `è¯­éŸ³æ¶ˆæ¯ (${audioBlob.size} bytes)`, messageData)

      console.log('[å½•éŸ³] å·²å‘é€è¯­éŸ³æ¶ˆæ¯')
    }

    reader.onerror = () => {
      console.error('[å½•éŸ³] è¯»å–éŸ³é¢‘å¤±è´¥')
    }

    reader.readAsDataURL(audioBlob)
  } catch (error) {
    console.error('[å½•éŸ³] å‘é€è¯­éŸ³æ¶ˆæ¯å¤±è´¥:', error)
  }
}

// æµ‹è¯•å‡½æ•°
const testMotion = () => {
  renderer.value?.playMotion('Idle', 0)
}

const testExpression = () => {
  renderer.value?.setExpression('f01')
}

const testPerform = () => {
  executePerformSequence([
    { type: 'text', content: 'ä½ å¥½ï¼è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯ã€‚', duration: 2000 },
    { type: 'motion', group: 'Idle', index: 0 },
    { type: 'expression', id: 'f01' }
  ])
}
</script>

<style scoped>
.app-container {
  width: 100%;
  height: 100%;
  position: relative;
}

.connection-status {
  position: fixed;
  top: 10px;
  right: 10px;
  padding: 8px 16px;
  background: rgba(0, 0, 0, 0.7);
  color: white;
  border-radius: 20px;
  font-size: 14px;
  z-index: 1000;
  transition: all 0.3s;
}

.connection-status.connected {
  background: rgba(0, 128, 0, 0.7);
}

.debug-panel {
  position: fixed;
  bottom: 20px;
  left: 20px;
  padding: 20px;
  background: rgba(0, 0, 0, 0.9);
  color: white;
  border-radius: 10px;
  z-index: 1000;
  max-width: 300px;
}

.debug-panel h3 {
  margin: 0 0 10px 0;
  font-size: 16px;
}

.debug-panel p {
  margin: 5px 0;
  font-size: 12px;
}

.debug-panel button {
  margin: 5px 5px 0 0;
  padding: 5px 10px;
  background: #4CAF50;
  color: white;
  border: none;
  border-radius: 4px;
  cursor: pointer;
  font-size: 12px;
}

.debug-panel button:hover {
  background: #45a049;
}

.image-send-button {
  position: fixed;
  bottom: 20px;
  right: 20px;
  width: 50px;
  height: 50px;
  background: rgba(255, 255, 255, 0.9);
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 24px;
  cursor: pointer;
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
  transition: all 0.3s;
  z-index: 1000;
}

.image-send-button:hover {
  background: rgba(255, 255, 255, 1);
  transform: scale(1.1);
  box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
}

.image-send-button:active {
  transform: scale(0.95);
}

.voice-record-button {
  position: fixed;
  bottom: 20px;
  right: 90px;
  width: 50px;
  height: 50px;
  background: rgba(255, 255, 255, 0.9);
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 24px;
  cursor: pointer;
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
  transition: all 0.3s;
  z-index: 1000;
  user-select: none;
}

.voice-record-button:hover {
  background: rgba(255, 255, 255, 1);
  transform: scale(1.1);
  box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
}

.voice-record-button.recording {
  background: rgba(255, 0, 0, 0.9);
  animation: pulse 1s infinite;
}

@keyframes pulse {
  0%, 100% {
    transform: scale(1);
  }
  50% {
    transform: scale(1.1);
  }
}
</style>
